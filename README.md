# APO v2 ‚Äî Autonomous Privacy Observability

> **What this is in one sentence:**
> An automated tool that visits any website like a real user, tests whether the site respects privacy choices (cookie consent, GPC opt-out), and produces a legal evidence report citing exact CCPA / GDPR violations and fines.

---

## üìÅ Folder Structure

Everything lives inside `apo_v2/`. The **backend** (Python/FastAPI) and the **frontend** (React) are both here.

```
apo_v2/
‚îÇ
‚îú‚îÄ‚îÄ backend.py              ‚Üê FastAPI server ‚Äî the bridge between UI and pipeline
‚îú‚îÄ‚îÄ main.py                 ‚Üê CLI entry point (run without a UI)
‚îú‚îÄ‚îÄ proxy_addon.py          ‚Üê mitmproxy plugin to capture raw network traffic
‚îú‚îÄ‚îÄ rules.sql               ‚Üê All CCPA & GDPR rules stored as SQL (25 rules)
‚îú‚îÄ‚îÄ requirements.txt        ‚Üê Python packages needed
‚îú‚îÄ‚îÄ .env.template           ‚Üê Copy this to .env and add your API keys
‚îÇ
‚îú‚îÄ‚îÄ agents/                 ‚Üê The 3-tier pipeline (runs the actual scan)
‚îÇ   ‚îú‚îÄ‚îÄ tier1_discovery.py  ‚Üê Crawls the website, maps all pages
‚îÇ   ‚îú‚îÄ‚îÄ tier2_interaction.py‚Üê Opens browser, runs 4 sessions, records traffic
‚îÇ   ‚îî‚îÄ‚îÄ tier3_observability.py ‚Üê Checks rules, generates violation report
‚îÇ
‚îú‚îÄ‚îÄ core/                   ‚Üê Shared utilities used by all agents
‚îÇ   ‚îú‚îÄ‚îÄ config.py           ‚Üê All settings in one place (URL, jurisdiction, etc.)
‚îÇ   ‚îú‚îÄ‚îÄ llm_router.py       ‚Üê Calls Claude / GPT-4o with auto-fallback
‚îÇ   ‚îú‚îÄ‚îÄ rules_db.py         ‚Üê Loads rules.sql into SQLite for fast lookup
‚îÇ   ‚îî‚îÄ‚îÄ tools.py            ‚Üê Browser tools (navigate, scroll, detect banners, etc.)
‚îÇ
‚îú‚îÄ‚îÄ apo/                    ‚Üê React frontend (the web UI)
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pages/          ‚Üê Main scan page
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/     ‚Üê UI blocks: ScanForm, TerminalLog, ViolationsTable, etc.
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ lib/api.ts      ‚Üê Calls backend API endpoints
‚îÇ   ‚îú‚îÄ‚îÄ package.json
‚îÇ   ‚îî‚îÄ‚îÄ index.html
‚îÇ
‚îî‚îÄ‚îÄ output/                 ‚Üê All scan results are saved here (auto-created)
    ‚îú‚îÄ‚îÄ interaction_graph.json      ‚Üê Map of all pages crawled
    ‚îú‚îÄ‚îÄ traffic_baseline.json       ‚Üê Network requests (no consent action)
    ‚îú‚îÄ‚îÄ traffic_compliance.json     ‚Üê Network requests (GPC signal ON)
    ‚îú‚îÄ‚îÄ session_state_baseline.json ‚Üê Cookies & storage from baseline
    ‚îú‚îÄ‚îÄ session_state_compliance.json
    ‚îú‚îÄ‚îÄ raw_traffic_proxy.jsonl     ‚Üê Deep traffic capture via mitmproxy
    ‚îî‚îÄ‚îÄ evidence_report.json        ‚Üê ‚úÖ Final violation report (what the UI shows)
```

---

## üîÑ How It Works ‚Äî The Full Pipeline

When a user submits a scan from the UI (or CLI), this is what happens step by step:

```
User enters URL + settings in the React UI
           ‚îÇ
           ‚ñº
    POST /api/scan  ‚Üí  backend.py
           ‚îÇ
           ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  TIER 1 ‚Äî Discovery Agent                    ‚îÇ
    ‚îÇ  tier1_discovery.py                          ‚îÇ
    ‚îÇ                                              ‚îÇ
    ‚îÇ  ‚Ä¢ Opens a browser with Playwright           ‚îÇ
    ‚îÇ  ‚Ä¢ Visits the target URL                     ‚îÇ
    ‚îÇ  ‚Ä¢ Finds all links, forms, buttons           ‚îÇ
    ‚îÇ  ‚Ä¢ Uses Claude AI to score each page's       ‚îÇ
    ‚îÇ    privacy risk (1‚Äì10)                       ‚îÇ
    ‚îÇ  ‚Ä¢ Saves a map of every page found           ‚îÇ
    ‚îÇ  ‚Üí Outputs: interaction_graph.json           ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
                       ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  TIER 2 ‚Äî Interaction Agent                  ‚îÇ
    ‚îÇ  tier2_interaction.py                        ‚îÇ
    ‚îÇ                                              ‚îÇ
    ‚îÇ  Runs 4 browser sessions (in order):         ‚îÇ
    ‚îÇ                                              ‚îÇ
    ‚îÇ  1. BASELINE      ‚Äî visits with no action    ‚îÇ
    ‚îÇ  2. CONSENT ACCEPT ‚Äî clicks "Accept All"     ‚îÇ
    ‚îÇ  3. CONSENT DECLINE ‚Äî clicks "No Thanks"     ‚îÇ
    ‚îÇ  4. GPC COMPLIANCE ‚Äî sends Sec-GPC: 1 header ‚îÇ
    ‚îÇ                                              ‚îÇ
    ‚îÇ  Each session records every network request: ‚îÇ
    ‚îÇ  ‚Ä¢ Which tracker companies were called?      ‚îÇ
    ‚îÇ  ‚Ä¢ Was PII (email, location) sent?           ‚îÇ
    ‚îÇ  ‚Ä¢ Did trackers still fire after "No Thanks"?‚îÇ
    ‚îÇ  ‚Ä¢ Did trackers fire before the user could   ‚îÇ
    ‚îÇ    even see the consent banner?              ‚îÇ
    ‚îÇ                                              ‚îÇ
    ‚îÇ  ‚Üí Outputs: traffic_*.json, session_*.json   ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
                       ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  TIER 3 ‚Äî Observability Agent                ‚îÇ
    ‚îÇ  tier3_observability.py                      ‚îÇ
    ‚îÇ                                              ‚îÇ
    ‚îÇ  Loads all 25 CCPA + GDPR rules from DB      ‚îÇ
    ‚îÇ  Runs each rule detector:                    ‚îÇ
    ‚îÇ                                              ‚îÇ
    ‚îÇ  CCPA checks:                                ‚îÇ
    ‚îÇ  ‚úì GPC signal not honored?                   ‚îÇ
    ‚îÇ  ‚úì "Do Not Sell" link missing?               ‚îÇ
    ‚îÇ  ‚úì No cookie/consent banner?                 ‚îÇ
    ‚îÇ  ‚úì PII in tracker requests?                  ‚îÇ
    ‚îÇ  ‚úì Sensitive data (health, finance) exposed? ‚îÇ
    ‚îÇ  ‚úì No privacy policy page?                   ‚îÇ
    ‚îÇ  ‚úì Consent wall (service gated behind Accept)?‚îÇ
    ‚îÇ  ‚úì Trackers active right after opt-out?      ‚îÇ
    ‚îÇ                                              ‚îÇ
    ‚îÇ  GDPR checks:                                ‚îÇ
    ‚îÇ  ‚úì Trackers loading before user sees banner? ‚îÇ
    ‚îÇ  ‚úì Cross-site tracking identifiers present?  ‚îÇ
    ‚îÇ  ‚úì Device fingerprinting detected?           ‚îÇ
    ‚îÇ  ‚úì Decline option absent or hidden?          ‚îÇ
    ‚îÇ  ‚úì Accept and Decline have same tracker load?‚îÇ
    ‚îÇ  ‚úì No transparency disclosure page?          ‚îÇ
    ‚îÇ  ‚úì No erasure / "delete my data" mechanism? ‚îÇ
    ‚îÇ  ‚úì Marketing trackers still firing after     ‚îÇ
    ‚îÇ    objection? (Art. 21 ‚Äî absolute right)     ‚îÇ
    ‚îÇ  ‚úì Automated profiling services detected?    ‚îÇ
    ‚îÇ  ‚úì PII sent to US servers without SCCs?      ‚îÇ
    ‚îÇ                                              ‚îÇ
    ‚îÇ  Uses GPT-4o to write plain-English          ‚îÇ
    ‚îÇ  explanations and fix recommendations        ‚îÇ
    ‚îÇ  for each violation found.                   ‚îÇ
    ‚îÇ                                              ‚îÇ
    ‚îÇ  ‚Üí Outputs: evidence_report.json             ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
                       ‚ñº
    Results stream back to the React UI via SSE
    (GET /api/stream/{scan_id})
    Final report shown in the Violations table
```

---

## üîå API Endpoints (backend.py)

| Endpoint | Method | What it does |
|---|---|---|
| `/api/scan` | POST | Start a new scan, returns `scan_id` |
| `/api/stream/{scan_id}` | GET | Live log stream (Server-Sent Events) |
| `/api/status/{scan_id}` | GET | Check progress % of each tier |
| `/api/results/{scan_id}` | GET | Get the final `evidence_report.json` |
| `/api/download/{filename}` | GET | Download any output file |
| `/health` | GET | Check if backend is alive |

---

## üóÑÔ∏è rules.sql ‚Äî The Legal Database

Contains **25 official rules** from CCPA and GDPR, each with:
- Rule ID (e.g. `CCPA-1798.120`, `GDPR-Art7.3`)
- Official section citation
- Full rule text
- Minimum and maximum fine amounts (in USD / EUR)

These are loaded into SQLite at scan time and matched against what was observed in Tier 2.

---

## ‚ñ∂Ô∏è How to Run

### Step 1 ‚Äî Set up Python environment (first time only)
```bash
cd apo_v2
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
playwright install chromium
```

### Step 2 ‚Äî Add API keys (optional but recommended)
```bash
cp .env.template .env
# Edit .env and add:
# ANTHROPIC_API_KEY=sk-ant-...
# OPENAI_API_KEY=sk-...
```
> Without API keys, the tool still works ‚Äî it skips AI analysis but runs all rule-based checks.

### Step 3 ‚Äî Start the backend
```bash
# Terminal 1
cd apo_v2
source venv/bin/activate
python backend.py
# ‚Üí Running on http://localhost:8000
```

### Step 4 ‚Äî Start the frontend
```bash
# Terminal 2
cd apo_v2/apo
npm install   # first time only
npm run dev
# ‚Üí Running on http://localhost:5173
```

### Step 5 ‚Äî Open the app
Go to **http://localhost:5173** in your browser, enter a URL, choose CCPA or GDPR, and click **Scan**.

---

### CLI mode (no UI needed)
```bash
cd apo_v2
source venv/bin/activate
python main.py --url https://www.example.com
python main.py --url https://www.example.com --skip-discovery  # reuse last crawl
```

---

## üìä What the Evidence Report Contains

`output/evidence_report.json` is structured like this:

```json
{
  "report_metadata": { "target", "jurisdiction", "generated_at" },
  "session_summary": {
    "baseline":          { "pages_visited": 5, "tracker_count": 40 },
    "consent_accepted":  { "pages_visited": 5, "tracker_count": 43 },
    "consent_declined":  { "pages_visited": 5, "tracker_count": 38 },
    "compliance_gpc_on": { "pages_visited": 5, "tracker_count": 35 }
  },
  "gpc_verdict": { "verdict": "NON-COMPLIANT", "domains_ignoring_gpc": ["..."] },
  "violation_summary": {
    "total": 6,
    "severity_breakdown": { "HIGH": 4, "MEDIUM": 2, "LOW": 0 },
    "max_potential_penalty_usd": 150000
  },
  "violations": [
    {
      "rule_id": "CCPA-1798.135b",
      "section": "¬ß1798.135(b)(1)",
      "violation_type": "GPC_NOT_HONORED",
      "severity": "HIGH",
      "evidence": { "tracker_domains": ["doubleclick.net", "..."] },
      "penalty_min_usd": 2500,
      "penalty_max_usd": 7500,
      "recommendation": "When Sec-GPC: 1 is received, stop all third-party tracker calls.",
      "llm_explanation": "Plain English explanation for non-lawyers...",
      "llm_technical_fix": "Exact code change engineers need to make..."
    }
  ]
}
```

---

## üß† AI Integration

| Where | Model | What it does |
|---|---|---|
| Tier 1 | Claude | Scores each crawled page for privacy risk (1‚Äì10), picks priority pages to visit next |
| Tier 2 | Claude | Plans which pages to focus the scan on; writes per-page compliance observations |
| Tier 3 | Claude | Reads the privacy policy and checks for required disclosures |
| Tier 3 | GPT-4o | Writes plain-English explanations and technical fix instructions for each violation |

If no API keys are provided, all AI steps are skipped and only the rule-based detectors run.

---

## ‚öôÔ∏è Key Settings (core/config.py)

| Setting | Default | Description |
|---|---|---|
| `ROOT_URL` | set by UI | The website to scan |
| `JURISDICTION` | `CCPA` | Which law to check against (`CCPA` or `GDPR`) |
| `MAX_PAGES` | `10` | How many pages to crawl (UI slider √ó 5) |
| `HEADLESS` | `True` | Set `False` to watch the browser as it scans |
| `SCROLL_STEPS` | `3` | How many times to scroll per page (triggers lazy trackers) |
| `TEMPORAL_LEAK_MS` | `500` | Trackers firing within this many ms of page load = violation |
